{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067d8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tf_keras import models, layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08434c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your two datasets\n",
    "df_purchase = pd.read_csv(\"User_product_purchase_details_p2.csv\")\n",
    "df_user = pd.read_csv(\"user_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f46bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after merge: (550068, 12)\n",
      "\n",
      "First few rows:\n",
      "   User_ID Product_ID City_Category Stay_In_Current_City_Years  \\\n",
      "0  1000001  P00069042             A                          2   \n",
      "1  1000001  P00248942             A                          2   \n",
      "2  1000001  P00087842             A                          2   \n",
      "3  1000001  P00085442             A                          2   \n",
      "4  1000002  P00285442             C                         4+   \n",
      "\n",
      "   Marital_Status  Product_Category_1  Product_Category_2  Product_Category_3  \\\n",
      "0               0                   3                 NaN                 NaN   \n",
      "1               0                   1                 6.0                14.0   \n",
      "2               0                  12                 NaN                 NaN   \n",
      "3               0                  12                14.0                 NaN   \n",
      "4               0                   8                 NaN                 NaN   \n",
      "\n",
      "   Purchase Gender   Age  Occupation  \n",
      "0      8370      F  0-17          10  \n",
      "1     15200      F  0-17          10  \n",
      "2      1422      F  0-17          10  \n",
      "3      1057      F  0-17          10  \n",
      "4      7969      M   55+          16  \n"
     ]
    }
   ],
   "source": [
    "# Merge on User_ID\n",
    "df = pd.merge(df_purchase, df_user, on=\"User_ID\", how=\"left\")\n",
    "\n",
    "print(\"Dataset shape after merge:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3487b94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "High_Value_Purchase\n",
      "0    360529\n",
      "1    189539\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create binary target\n",
    "df[\"High_Value_Purchase\"] = (df[\"Purchase\"] >= 10000).astype(int)\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[\"High_Value_Purchase\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3500a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "df = df.drop([\"Product_ID\", \"User_ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52ee0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values before filling:\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            173638\n",
      "Product_Category_3            383247\n",
      "Purchase                           0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "High_Value_Purchase                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"\\nMissing values before filling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b42839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape after encoding: (550068, 20)\n",
      "\n",
      "Column names after encoding:\n",
      "['Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase', 'Occupation', 'High_Value_Purchase', 'Gender_M', 'Age_18-25', 'Age_26-35', 'Age_36-45', 'Age_46-50', 'Age_51-55', 'Age_55+', 'City_Category_B', 'City_Category_C', 'Stay_In_Current_City_Years_1', 'Stay_In_Current_City_Years_2', 'Stay_In_Current_City_Years_3', 'Stay_In_Current_City_Years_4+', 'Marital_Status_1']\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables using one-hot encoding\n",
    "categorical_cols = ['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
    "\n",
    "# Check which categorical columns exist in the dataframe\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "df = pd.get_dummies(df, columns=existing_categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"\\nDataset shape after encoding:\", df.shape)\n",
    "print(\"\\nColumn names after encoding:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2d4488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 440054\n",
      "Test set size: 110014\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop([\"High_Value_Purchase\", \"Purchase\"], axis=1)\n",
    "y = df[\"High_Value_Purchase\"]\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4443d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42f8d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LOGISTIC REGRESSION MODEL\n",
      "==================================================\n",
      "\n",
      "LR Accuracy: 0.7661752140636646\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64702  7404]\n",
      " [18320 19588]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83     72106\n",
      "           1       0.73      0.52      0.60     37908\n",
      "\n",
      "    accuracy                           0.77    110014\n",
      "   macro avg       0.75      0.71      0.72    110014\n",
      "weighted avg       0.76      0.77      0.75    110014\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "               feature  importance\n",
      "0   Product_Category_1    0.845970\n",
      "2   Product_Category_3    0.430037\n",
      "4             Gender_M    0.110769\n",
      "12     City_Category_C    0.109819\n",
      "7            Age_36-45    0.076448\n",
      "6            Age_26-35    0.072334\n",
      "9            Age_51-55    0.064008\n",
      "8            Age_46-50    0.043494\n",
      "11     City_Category_B    0.036939\n",
      "5            Age_18-25    0.036241\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION BASELINE\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "log = LogisticRegression(max_iter=2000, random_state=42)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "pred_lr = log.predict(X_test_scaled)\n",
    "pred_lr_proba = log.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nLR Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.abs(log.coef_[0])\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33bfcf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MLP NEURAL NETWORK MODEL\n",
      "==================================================\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\weekly\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\weekly\\.venv\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP (KERAS) MODEL\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MLP NEURAL NETWORK MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Build MLP model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"binary_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96a2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1216      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3329 (13.00 KB)\n",
      "Trainable params: 3329 (13.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training MLP...\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\weekly\\.venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\weekly\\.venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11002/11002 [==============================] - 10s 896us/step - loss: 0.4037 - accuracy: 0.8285 - val_loss: 0.3326 - val_accuracy: 0.8681\n",
      "Epoch 2/20\n",
      "11002/11002 [==============================] - 9s 835us/step - loss: 0.3031 - accuracy: 0.8778 - val_loss: 0.2882 - val_accuracy: 0.8862\n",
      "Epoch 3/20\n",
      "11002/11002 [==============================] - 9s 830us/step - loss: 0.2873 - accuracy: 0.8852 - val_loss: 0.2807 - val_accuracy: 0.8903\n",
      "Epoch 4/20\n",
      "11002/11002 [==============================] - 8s 756us/step - loss: 0.2795 - accuracy: 0.8874 - val_loss: 0.2750 - val_accuracy: 0.8866\n",
      "Epoch 5/20\n",
      "11002/11002 [==============================] - 9s 812us/step - loss: 0.2730 - accuracy: 0.8902 - val_loss: 0.2671 - val_accuracy: 0.8922\n",
      "Epoch 6/20\n",
      "11002/11002 [==============================] - 10s 909us/step - loss: 0.2679 - accuracy: 0.8932 - val_loss: 0.2782 - val_accuracy: 0.8884\n",
      "Epoch 7/20\n",
      "11002/11002 [==============================] - 9s 826us/step - loss: 0.2652 - accuracy: 0.8939 - val_loss: 0.2622 - val_accuracy: 0.8947\n",
      "Epoch 8/20\n",
      "11002/11002 [==============================] - 9s 793us/step - loss: 0.2638 - accuracy: 0.8941 - val_loss: 0.2596 - val_accuracy: 0.8967\n",
      "Epoch 9/20\n",
      "11002/11002 [==============================] - 9s 781us/step - loss: 0.2628 - accuracy: 0.8942 - val_loss: 0.2589 - val_accuracy: 0.8960\n",
      "Epoch 10/20\n",
      "11002/11002 [==============================] - 8s 761us/step - loss: 0.2612 - accuracy: 0.8947 - val_loss: 0.2576 - val_accuracy: 0.8969\n",
      "Epoch 11/20\n",
      "11002/11002 [==============================] - 8s 743us/step - loss: 0.2597 - accuracy: 0.8953 - val_loss: 0.2579 - val_accuracy: 0.8978\n",
      "Epoch 12/20\n",
      "11002/11002 [==============================] - 8s 727us/step - loss: 0.2587 - accuracy: 0.8953 - val_loss: 0.2664 - val_accuracy: 0.8912\n",
      "Epoch 13/20\n",
      "11002/11002 [==============================] - 9s 836us/step - loss: 0.2575 - accuracy: 0.8955 - val_loss: 0.2543 - val_accuracy: 0.8977\n",
      "Epoch 14/20\n",
      "11002/11002 [==============================] - 8s 756us/step - loss: 0.2569 - accuracy: 0.8954 - val_loss: 0.2570 - val_accuracy: 0.8982\n",
      "Epoch 15/20\n",
      "11002/11002 [==============================] - 9s 781us/step - loss: 0.2564 - accuracy: 0.8958 - val_loss: 0.2576 - val_accuracy: 0.8978\n",
      "Epoch 16/20\n",
      "11002/11002 [==============================] - 9s 824us/step - loss: 0.2560 - accuracy: 0.8955 - val_loss: 0.2559 - val_accuracy: 0.8947\n",
      "Epoch 17/20\n",
      "11002/11002 [==============================] - 9s 815us/step - loss: 0.2556 - accuracy: 0.8957 - val_loss: 0.2523 - val_accuracy: 0.8983\n",
      "Epoch 18/20\n",
      "11002/11002 [==============================] - 9s 810us/step - loss: 0.2552 - accuracy: 0.8959 - val_loss: 0.2543 - val_accuracy: 0.8953\n",
      "Epoch 19/20\n",
      "11002/11002 [==============================] - 9s 856us/step - loss: 0.2549 - accuracy: 0.8962 - val_loss: 0.2515 - val_accuracy: 0.8981\n",
      "Epoch 20/20\n",
      "11002/11002 [==============================] - 8s 766us/step - loss: 0.2545 - accuracy: 0.8964 - val_loss: 0.2532 - val_accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining MLP...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d965d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "loss, acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"\\nMLP Test Accuracy: {acc:.4f}\")\n",
    "print(f\"MLP Test Loss: {loss:.4f}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "pred_mlp = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "pred_mlp_proba = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, pred_mlp))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6892e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL COMPARISON\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON - ALL METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate all metrics for both models\n",
    "lr_accuracy = accuracy_score(y_test, pred_lr)\n",
    "lr_precision = precision_score(y_test, pred_lr)\n",
    "lr_recall = recall_score(y_test, pred_lr)\n",
    "lr_f1 = f1_score(y_test, pred_lr)\n",
    "lr_auc = roc_auc_score(y_test, pred_lr_proba)\n",
    "\n",
    "mlp_accuracy = accuracy_score(y_test, pred_mlp)\n",
    "mlp_precision = precision_score(y_test, pred_mlp)\n",
    "mlp_recall = recall_score(y_test, pred_mlp)\n",
    "mlp_f1 = f1_score(y_test, pred_mlp)\n",
    "mlp_auc = roc_auc_score(y_test, pred_mlp_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pl.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'Logistic Regression': [lr_accuracy, lr_precision, lr_recall, lr_f1, lr_auc],\n",
    "    'MLP Neural Network': [mlp_accuracy, mlp_precision, mlp_recall, mlp_f1, mlp_auc],\n",
    "    'Difference': [\n",
    "        mlp_accuracy - lr_accuracy,\n",
    "        mlp_precision - lr_precision,\n",
    "        mlp_recall - lr_recall,\n",
    "        mlp_f1 - lr_f1,\n",
    "        mlp_auc - lr_auc\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if mlp_accuracy > lr_accuracy:\n",
    "    print(\"\\n✓ MLP performed better overall!\")\n",
    "    print(\"Reason: Neural networks can capture non-linear relationships\")\n",
    "    print(\"between features that logistic regression cannot model.\")\n",
    "elif lr_accuracy > mlp_accuracy:\n",
    "    print(\"\\n✓ Logistic Regression performed better overall!\")\n",
    "    print(\"Reason: The relationship might be primarily linear, or the\")\n",
    "    print(\"neural network may be overfitting the training data.\")\n",
    "else:\n",
    "    print(\"\\n✓ Both models performed equally!\")\n",
    "    print(\"Reason: The problem might have simple linear patterns that\")\n",
    "    print(\"both models can capture effectively.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"End of analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
